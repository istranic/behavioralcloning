{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, MaxPooling2D, Lambda\n",
    "import pickle\n",
    "import csv\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7080, 24, 64, 3)\n",
      "(7080,)\n",
      "(24, 64, 3)\n",
      "(24, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "data_dir= \"data/\"\n",
    "data_file = \"driving_log.csv\"\n",
    "\n",
    "image_file_list=[]\n",
    "center_image_data_list=[]\n",
    "steering_angles_list=[]\n",
    "\n",
    "image_y = 24\n",
    "image_x = 64\n",
    "\n",
    "image_y_orig=160\n",
    "image_x_orig=320 \n",
    "\n",
    "min_angle_threshold=0.01\n",
    "max_angle_threshold=.5\n",
    "\n",
    "\n",
    "with open(data_dir+data_file, mode='rt') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "#         #print(row[3])\n",
    "#         #print(row[0])\n",
    "#         image=cv2.imread(row[0])\n",
    "#         print(\"Original image is shape:\", image.shape)\n",
    "#         cropped=image[round(0.25*image_y_orig):(image_y_orig),0:(image_x_orig),:]\n",
    "#         print(\"Cropped image is shape:\", cropped.shape)\n",
    "#         cv2.imshow('original image',image)\n",
    "#         cv2.waitKey() \n",
    "#         cv2.imshow('cropped  image',cropped)\n",
    "#         cv2.waitKey() \n",
    "        \n",
    "#         image_resized=cv2.resize(cv2.imread(row[0])[round(0.25*image_y_orig):(image_y_orig),0:(image_x_orig),:],(image_x,image_y))\n",
    "#         #print(\"Resized image is shape:\", image_resized.shape)\n",
    "#         cv2.imshow('cropped and resized 1',image_resized)\n",
    "#         cv2.waitKey()\n",
    "#         #cv2.destroyAllWindows()\n",
    "#         print(data_dir+row[0])\n",
    "        angle = float(row[3])\n",
    "        \n",
    "        if abs(angle)>=min_angle_threshold and abs(angle)<=max_angle_threshold:\n",
    "            center_image_data_list.append(cv2.resize(cv2.imread(data_dir+row[0])[round(0.25*image_y_orig):(image_y_orig),0:(image_x_orig),:],(image_x,image_y)))\n",
    "            steering_angles_list.append(float(row[3]))      \n",
    "        \n",
    "            center_image_data_list.append(cv2.flip(cv2.resize(cv2.imread(data_dir+row[0])\n",
    "                                                 [round(0.25*image_y_orig):(image_y_orig),0:(image_x_orig),:],(image_x,image_y)),1))\n",
    "            steering_angles_list.append(float(row[3])*(-1.0))\n",
    "        \n",
    "# cv2.imshow('cropped and resized',center_image_data_list[0])   \n",
    "# cv2.waitKey()\n",
    "# cv2.imshow('cropped and resized and flipped',center_image_data_list[1])   \n",
    "# cv2.waitKey()\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.imwrite('lobes.jpg', center_image_data_list[0]) \n",
    "# cv2.imwrite('lobes2.jpg', center_image_data_list[1]) \n",
    "        \n",
    "        \n",
    "center_image_data=np.asarray(center_image_data_list)\n",
    "steering_angles=np.asarray(steering_angles_list)     \n",
    "\n",
    "input_shape=center_image_data[0].shape\n",
    "print(center_image_data.shape)\n",
    "print(steering_angles.shape)\n",
    "print(center_image_data[0].shape)\n",
    "print(input_shape)\n",
    "\n",
    "#cv2.imshow('image',center_image_data[0])\n",
    "#cv2.waitKey()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',center_image_data[0])\n",
    "cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "testimage=cv2.cvtColor(center_image_data[0], cv2.COLOR_BGR2RGB)\n",
    "\n",
    "testimageback=cv2.cvtColor(testimage, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "plt.imshow(testimage) \n",
    "plt.show()\n",
    "\n",
    "print(testimage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',testimageback)\n",
    "cv2.waitKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(steering_angles[1000:1005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_savepath = \"CompleteModel.h5\"\n",
    "model_weights_savepath = \"model.h5\"\n",
    "model_json_savepath = \"model.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Conv1_Channels = 24\n",
    "Conv1_Pixels=4\n",
    "Conv1_Stride=2\n",
    "Conv2_Channels = 32\n",
    "Conv2_Pixels=4\n",
    "Conv2_Stride=2\n",
    "Conv3_Channels = 32\n",
    "Conv3_Pixels=3\n",
    "Conv3_Stride=2\n",
    "fc1_neurons=100\n",
    "fc2_neurons=25\n",
    "fc3_neurons=5\n",
    "fc4_neurons=1\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - 1.,input_shape=input_shape))\n",
    "model.add(Convolution2D(Conv1_Channels, Conv1_Pixels, Conv1_Pixels,\n",
    "                        border_mode='valid', subsample=(Conv1_Stride,Conv1_Stride)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(Conv2_Channels, Conv2_Pixels, Conv2_Pixels,\n",
    "                        border_mode='valid', subsample=(Conv2_Stride,Conv2_Stride)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(Conv3_Channels, Conv3_Pixels, Conv3_Pixels,\n",
    "                        border_mode='valid', subsample=(Conv3_Stride,Conv3_Stride)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(fc1_neurons))\n",
    "# model.add(Activation('relu'))\n",
    "model.add(Dense(fc2_neurons))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(fc3_neurons))\n",
    "model.add(Dense(fc4_neurons))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "nb_epoch = 5\n",
    "\n",
    "history = model.fit(center_image_data, steering_angles,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1)\n",
    "\n",
    "#history = model.fit_generator(generator, samples_per_epoch, nb_epoch=nb_epoch, verbose=1)\n",
    "\n",
    "\n",
    "#del model  # deletes the existing model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(center_image_data, steering_angles, verbose=0)\n",
    "prediction = model.predict(center_image_data, verbose=0)\n",
    "\n",
    "print(\"Model loss is:\", score[0])\n",
    "print(\"Model predictions are:\", prediction)\n",
    "print(\"Input steering angles are:\", steering_angles)\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(model_savepath)  # creates a HDF5 file 'my_model.h5'\n",
    "model.save_weights(model_weights_savepath)\n",
    "json_string = model.to_json()\n",
    "with open(model_json_savepath, 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = load_model(model_savepath)\n",
    "\n",
    "batch_size = 100\n",
    "nb_epoch = 1\n",
    "\n",
    "history = model.fit(center_image_data, steering_angles,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(center_image_data, steering_angles, verbose=0)\n",
    "prediction = model.predict(center_image_data, verbose=0)\n",
    "\n",
    "print(\"Model loss is:\", score[0])\n",
    "print(\"Model predictions are:\", prediction)\n",
    "print(\"Input steering angles are:\", steering_angles)\n",
    "# print('Test score:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save(model_savepath)  # creates a HDF5 file 'my_model.h5'\n",
    "model.save_weights(model_weights_savepath)\n",
    "json_string = model.to_json()\n",
    "with open(model_json_savepath, 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def batch_generator(driving_log, batch_size=32):\n",
    "    num_rows = <figure out total number of rows in csv>\n",
    "    train_images = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    train_steering = np.zeros(batch_size)\n",
    "    ctr = None\n",
    "    while 1:        \n",
    "        for j in range(batch_size):\n",
    "            if ctr is None or ctr >= num_rows:\n",
    "                ctr = 0     # Initialize counter or reset counter if over bounds\n",
    "            train_images[j], train_steering[j] = <load data from row number \"ctr\" in the CSV file> \n",
    "            ctr += 1\n",
    "        yield train_images, train_steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nvidia Model\n",
    "\n",
    "# Conv1_Channels = 24\n",
    "# Conv1_Pixels=5\n",
    "# Conv1_Stride=2\n",
    "# Conv2_Channels = 36\n",
    "# Conv2_Pixels=5\n",
    "# Conv2_Stride=2\n",
    "# Conv3_Channels = 48\n",
    "# Conv3_Pixels=5\n",
    "# Conv3_Stride=2\n",
    "# Conv4_Channels = 64\n",
    "# Conv4_Pixels=3\n",
    "# Conv4_Stride=2\n",
    "# Conv5_Channels = 64\n",
    "# Conv5_Pixels=3\n",
    "# Conv5_Stride=1\n",
    "# fc1_neurons=100\n",
    "# fc2_neurons=50\n",
    "# fc3_neurons=10\n",
    "# fc4_neurons=1\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Lambda(lambda x: x/127.5 - 1.,input_shape=input_shape))\n",
    "# model.add(Convolution2D(Conv1_Channels, Conv1_Pixels, Conv1_Pixels,\n",
    "#                         border_mode='valid', subsample=(Conv1_Stride,Conv1_Stride)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(Conv2_Channels, Conv2_Pixels, Conv2_Pixels,\n",
    "#                         border_mode='valid', subsample=(Conv2_Stride,Conv2_Stride)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(Conv3_Channels, Conv3_Pixels, Conv3_Pixels,\n",
    "#                         border_mode='valid', subsample=(Conv3_Stride,Conv3_Stride)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(Conv4_Channels, Conv4_Pixels, Conv4_Pixels,\n",
    "#                         border_mode='valid', subsample=(Conv4_Stride,Conv4_Stride)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Convolution2D(Conv5_Channels, Conv5_Pixels, Conv5_Pixels,\n",
    "#                         border_mode='valid', subsample=(Conv5_Stride,Conv5_Stride)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(fc1_neurons))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(fc2_neurons))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(fc3_neurons))\n",
    "# model.add(Dense(fc4_neurons))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
